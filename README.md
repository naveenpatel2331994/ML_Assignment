# Bank Marketing - ML Assignment

Quick CLI and Makefile to run dataset download, EDA, and baseline model training.

Usage:

Install dependencies:
```
python3 -m pip install --user -r requirements.txt
```

Run via Make:
```
make deps      # install deps
make download  # download dataset from UCI
make eda       # run EDA (depends on download)
make train     # run training (depends on download)
make all       # deps + download + eda + train
```

Or use the small CLI:
```
python3 cli.py deps
python3 cli.py download
python3 cli.py eda
python3 cli.py train
python3 cli.py all
```

Files written by scripts:
- `datasets/classification/bank-full.csv`
- `reports/eda_bank/` (plots and summaries)
- `reports/models_baseline/` (models, ROC plots, results)

## Model Comparison

ML Model Name | Accuracy | AUC | Precision | Recall | F1 | MCC
:---|:---:|:---:|:---:|:---:|:---:|:---:
Logistic Regression | 0.846 | 0.908 | 0.418 | 0.815 | 0.553 | 0.509
Decision Tree | 0.877 | 0.692 | 0.474 | 0.451 | 0.462 | 0.393
kNN | 0.896 | 0.828 | 0.599 | 0.340 | 0.434 | 0.400
Naive Bayes (Gaussian) | 0.855 | 0.810 | 0.406 | 0.520 | 0.456 | 0.377
Random Forest (Ensemble) | 0.904 | 0.930 | 0.686 | 0.333 | 0.448 | 0.434
XGBoost (Ensemble) | Not run | Not run | Not run | Not run | Not run | Not run

> Results sourced from `reports/models_all/results_all.json` generated by `train_all_models.py`.

## Observations on Model Performance

ML Model Name | Observation about model performance
:---|:---
Logistic Regression | Strong recall (0.815) and the highest MCC (0.509) — good balanced performer for detecting positives at cost of some false positives.
Decision Tree | Decent accuracy but low AUC (0.692) and moderate MCC — prone to overfitting and lower discrimination.
kNN | High accuracy and precision but low recall (0.340) — conservative positive predictions; suitable when false positives are costly.
Naive Bayes | Balanced recall (0.520) with moderate precision — simple baseline with reasonable performance and fast inference.
Random Forest (Ensemble) | Highest accuracy and AUC (0.904, 0.930) with strong precision but low recall — very good at ranking (AUC) but conservative in positive predictions.



